{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55af9979",
   "metadata": {},
   "source": [
    "### Predictive Maintanence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c994eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eecbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('ai4i2020.csv')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81a3011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UDI', 'Product ID', 'Type', 'Air temperature [K]',\n",
       "       'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]',\n",
       "       'Tool wear [min]', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF',\n",
       "       'RNF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5541c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['UDI', 'Product ID'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee95144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Machine failure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297e7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_failure= dataset[['Type', 'Air temperature [K]','Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]','Tool wear [min]', 'Machine failure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696a1d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>M</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>H</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>M</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1645</td>\n",
       "      <td>33.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>H</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>M</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0       M                298.1                    308.6   \n",
       "1       L                298.2                    308.7   \n",
       "2       L                298.1                    308.5   \n",
       "3       L                298.2                    308.6   \n",
       "4       L                298.2                    308.7   \n",
       "...   ...                  ...                      ...   \n",
       "9995    M                298.8                    308.4   \n",
       "9996    H                298.9                    308.4   \n",
       "9997    M                299.0                    308.6   \n",
       "9998    H                299.0                    308.7   \n",
       "9999    M                299.0                    308.7   \n",
       "\n",
       "      Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  \n",
       "0                       1551         42.8                0                0  \n",
       "1                       1408         46.3                3                0  \n",
       "2                       1498         49.4                5                0  \n",
       "3                       1433         39.5                7                0  \n",
       "4                       1408         40.0                9                0  \n",
       "...                      ...          ...              ...              ...  \n",
       "9995                    1604         29.5               14                0  \n",
       "9996                    1632         31.8               17                0  \n",
       "9997                    1645         33.4               22                0  \n",
       "9998                    1408         48.5               25                0  \n",
       "9999                    1500         40.2               30                0  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Machine_failure.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f146ca",
   "metadata": {},
   "source": [
    "The dataset consists of 10 000 data points stored as rows with 14 features in columns\n",
    "UID: unique identifier ranging from 1 to 10000\n",
    "product ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "air temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
    "process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n",
    "rotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noise\n",
    "torque [Nm]: torque values are normally distributed around 40 Nm with a Ïƒ = 10 Nm and no negative values.\n",
    "tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a\n",
    "'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.\n",
    "\n",
    "The machine failure consists of five independent failure modes\n",
    "tool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 â€“ 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).\n",
    "heat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the toolâ€™s rotational speed is below 1380 rpm. This is the case for 115 data points.\n",
    "power failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.\n",
    "overstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.\n",
    "random failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.\n",
    "\n",
    "If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ab9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451e9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea99d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-22c53d6e9c3c>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Machine_failure['Type']=label_encoder.fit_transform(Machine_failure['Type'])\n"
     ]
    }
   ],
   "source": [
    "Machine_failure['Type']=label_encoder.fit_transform(Machine_failure['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7467a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Machine_failure.drop('Machine failure' ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cdf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Machine_failure['Machine failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef0e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.7, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5182b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b521f60",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8db38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad877bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a41944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_fit=model_linear.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7179b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficient of model : [-0.00411981  0.02413001 -0.02273087  0.00058221  0.01223167  0.00027603]\n",
      "\n",
      "Intercept of model -1.568901210570032\n"
     ]
    }
   ],
   "source": [
    "# coefficeints of the trained model\n",
    "print('\\nCoefficient of model :', model_linear_fit.coef_)\n",
    "\n",
    "# intercept of the model\n",
    "print('\\nIntercept of model',model_linear_fit.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6af4039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coeffiecient of Linear Regression model of trainning dataset [ 0.12861153  0.02065238  0.06706082 ...  0.07710044  0.0643638\n",
      " -0.10266547]\n",
      "\n",
      "RMSE of Linear Regression model of trainning dataset :  0.168155184138138\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "predict_train = model_linear_fit.predict(x_train)\n",
    "print('\\nCoeffiecient of Linear Regression model of trainning dataset',predict_train) \n",
    "\n",
    "# Root Mean Squared Error on training dataset\n",
    "rmse_train = mean_squared_error(y_train,predict_train)**(0.5)\n",
    "print('\\nRMSE of Linear Regression model of trainning dataset : ', rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc2e082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction of linear Regression on test dataset [ 0.00083623 -0.00616276 -0.02909271 ...  0.07104901  0.03738231\n",
      " -0.05149118]\n",
      "\n",
      "RMSE on test dataset of Linear Regression :  0.17017998823693256\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the testing dataset\n",
    "predict_test = model_linear_fit.predict(x_test)\n",
    "print('\\nPrediction of linear Regression on test dataset',predict_test) \n",
    "\n",
    "# Root Mean Squared Error on testing dataset\n",
    "rmse_test = mean_squared_error(y_test,predict_test)**(0.5)\n",
    "print('\\nRMSE on test dataset of Linear Regression : ', rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185f742",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b02689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "845c961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log=LogisticRegression()\n",
    "model_log_fit= model_log.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c68bf866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coefficient of Logistic Regression [[-0.06296257  1.12654322 -1.21480807  0.01284425  0.30290127  0.01468607]]\n",
      "\n",
      " Intercept of Logistic Regression [-0.00906959]\n"
     ]
    }
   ],
   "source": [
    "#coeff of logistc regression\n",
    "\n",
    "print(\"\\n Coefficient of Logistic Regression\" , model_log_fit.coef_)\n",
    "print(\"\\n Intercept of Logistic Regression\" , model_log_fit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5325665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of  Logistic Regression on trainning dataset 97.1 %\n"
     ]
    }
   ],
   "source": [
    "##training accuracy\n",
    "predict_log_train=model_log_fit.predict(x_train)\n",
    "Accuracy_logistic_train= accuracy_score(y_train,predict_log_train)\n",
    "print(\"\\n Accuracy of  Logistic Regression on trainning dataset\",Accuracy_logistic_train*100,\"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "782c6765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of Logistic Regression on test dataset 96.85714285714285 %\n"
     ]
    }
   ],
   "source": [
    "## testing accuracy\n",
    "\n",
    "predict_log_test=model_log_fit.predict(x_test)\n",
    "Accuracy_logistic_test= accuracy_score(y_test,predict_log_test)\n",
    "print(\"\\n Accuracy of Logistic Regression on test dataset\" , Accuracy_logistic_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a713c19e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-54d2e4fd8fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_log_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "model_log_fit.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1688205",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e38e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(kernel='linear', random_state=0)  \n",
    "model_svm_fit=model_svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "496c38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of SVM on trainning dataset 97.23333333333333 %\n"
     ]
    }
   ],
   "source": [
    "##training accuracy\n",
    "predict_svm_train=model_svm_fit.predict(x_train)\n",
    "Accuracy_svm_train= accuracy_score(y_train,predict_svm_train)\n",
    "print(\"\\n Accuracy of SVM on trainning dataset\",Accuracy_svm_train*100,\"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78d8d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of  SVM on trainning dataset 97.02857142857142 %\n"
     ]
    }
   ],
   "source": [
    "##testing accuracy\n",
    "\n",
    "predict_svm_test=model_svm_fit.predict(x_test)\n",
    "Accuracy_svm_test= accuracy_score(y_test,predict_svm_test)\n",
    "print(\"\\n Accuracy of  SVM on trainning dataset\",Accuracy_svm_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ac3b0",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ebf131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "model_knn= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "model_knn_fit=model_knn.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5836410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of KNN on trainning dataset 97.23333333333333 %\n",
      "\n",
      " Accuracy of  KNN on test dataset 96.87142857142858 %\n"
     ]
    }
   ],
   "source": [
    "##training accuracy\n",
    "predict_knn_train=model_knn_fit.predict(x_train)\n",
    "Accuracy_knn_train= accuracy_score(y_train,predict_svm_train)\n",
    "print(\"\\n Accuracy of KNN on trainning dataset\",Accuracy_knn_train*100,\"%\" )\n",
    "\n",
    "##testing accuracy\n",
    "\n",
    "predict_knn_test=model_knn_fit.predict(x_test)\n",
    "Accuracy_knn_test= accuracy_score(y_test,predict_knn_test)\n",
    "print(\"\\n Accuracy of  KNN on test dataset\",Accuracy_knn_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b74680",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569fd1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "model_dtc= DecisionTreeClassifier(criterion='entropy', random_state=0)  \n",
    "model_dtc_fit=model_dtc.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56b2bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of Decision Tree Classifier on trainning dataset 100.0 %\n",
      "\n",
      " Accuracy of  Decision Tree Classifier on test dataset 97.68571428571428 %\n"
     ]
    }
   ],
   "source": [
    "##training accuracy\n",
    "predict_dtc_train=model_dtc_fit.predict(x_train)\n",
    "Accuracy_dtc_train= accuracy_score(y_train,predict_dtc_train)\n",
    "print(\"\\n Accuracy of Decision Tree Classifier on trainning dataset\",Accuracy_dtc_train*100,\"%\" )\n",
    "\n",
    "##testing accuracy\n",
    "\n",
    "predict_dtc_test=model_dtc_fit.predict(x_test)\n",
    "Accuracy_dtc_test= accuracy_score(y_test,predict_dtc_test)\n",
    "print(\"\\n Accuracy of  Decision Tree Classifier on test dataset\",Accuracy_dtc_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa18163",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03d5eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgb= DecisionTreeClassifier(criterion='entropy', random_state=0)  \n",
    "model_xgb_fit=model_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "057062d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of XGBoost Classifier on trainning dataset 100.0 %\n",
      "\n",
      " Accuracy of  XGBoost Classifier on test dataset 97.68571428571428 %\n"
     ]
    }
   ],
   "source": [
    "#training accuracy\n",
    "predict_xgb_train=model_xgb_fit.predict(x_train)\n",
    "Accuracy_xgb_train= accuracy_score(y_train,predict_xgb_train)\n",
    "print(\"\\n Accuracy of XGBoost Classifier on trainning dataset\",Accuracy_xgb_train*100,\"%\" )\n",
    "\n",
    "##testing accuracy\n",
    "\n",
    "predict_xgb_test=model_xgb_fit.predict(x_test)\n",
    "Accuracy_xgb_test= accuracy_score(y_test,predict_xgb_test)\n",
    "print(\"\\n Accuracy of  XGBoost Classifier on test dataset\",Accuracy_xgb_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a819004",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09c9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7d1a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of AdaBoost Classifier on trainning dataset 98.2 %\n",
      "\n",
      " Accuracy of  AdaBoost Classifier on test dataset 97.32857142857144 %\n"
     ]
    }
   ],
   "source": [
    "model_ada= AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)  \n",
    "model_ada_fit=model_ada.fit(x_train, y_train)\n",
    "#training accuracy\n",
    "predict_ada_train=model_ada_fit.predict(x_train)\n",
    "Accuracy_ada_train= accuracy_score(y_train,predict_ada_train)\n",
    "print(\"\\n Accuracy of AdaBoost Classifier on trainning dataset\",Accuracy_ada_train*100,\"%\" )\n",
    "\n",
    "##testing accuracy\n",
    "\n",
    "predict_ada_test=model_ada_fit.predict(x_test)\n",
    "Accuracy_ada_test= accuracy_score(y_test,predict_ada_test)\n",
    "print(\"\\n Accuracy of  AdaBoost Classifier on test dataset\",Accuracy_ada_test*100,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffcc16",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e5743d",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7c7bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "94/94 [==============================] - 1s 1ms/step - loss: 81.9446 - accuracy: 0.3840\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6138 - accuracy: 0.9623\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2257 - accuracy: 0.9467\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9564 - accuracy: 0.9460\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 0s 990us/step - loss: 0.7037 - accuracy: 0.9450\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.9493\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9590\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9677\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9683\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1181 - accuracy: 0.9687\n",
      "Epoch 11/200\n",
      "94/94 [==============================] - 0s 965us/step - loss: 0.1133 - accuracy: 0.9680\n",
      "Epoch 12/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1270 - accuracy: 0.9687\n",
      "Epoch 13/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1241 - accuracy: 0.9687\n",
      "Epoch 14/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1186 - accuracy: 0.9690\n",
      "Epoch 15/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1327 - accuracy: 0.9680\n",
      "Epoch 16/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1213 - accuracy: 0.9673\n",
      "Epoch 17/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1158 - accuracy: 0.9687\n",
      "Epoch 18/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1134 - accuracy: 0.9690\n",
      "Epoch 19/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9683\n",
      "Epoch 20/200\n",
      "94/94 [==============================] - 0s 954us/step - loss: 0.1222 - accuracy: 0.9693\n",
      "Epoch 21/200\n",
      "94/94 [==============================] - 0s 933us/step - loss: 0.1105 - accuracy: 0.9697\n",
      "Epoch 22/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1156 - accuracy: 0.9680\n",
      "Epoch 23/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1159 - accuracy: 0.9687\n",
      "Epoch 24/200\n",
      "94/94 [==============================] - 0s 987us/step - loss: 0.1136 - accuracy: 0.9693\n",
      "Epoch 25/200\n",
      "94/94 [==============================] - 0s 976us/step - loss: 0.1129 - accuracy: 0.9693\n",
      "Epoch 26/200\n",
      "94/94 [==============================] - 0s 954us/step - loss: 0.1115 - accuracy: 0.9687\n",
      "Epoch 27/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1152 - accuracy: 0.9687\n",
      "Epoch 28/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1200 - accuracy: 0.9680\n",
      "Epoch 29/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1137 - accuracy: 0.9683\n",
      "Epoch 30/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1124 - accuracy: 0.9673\n",
      "Epoch 31/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9703\n",
      "Epoch 32/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1196 - accuracy: 0.9667\n",
      "Epoch 33/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1251 - accuracy: 0.9690\n",
      "Epoch 34/200\n",
      "94/94 [==============================] - 0s 922us/step - loss: 0.1346 - accuracy: 0.9653\n",
      "Epoch 35/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1095 - accuracy: 0.9680\n",
      "Epoch 36/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1189 - accuracy: 0.9693\n",
      "Epoch 37/200\n",
      "94/94 [==============================] - 0s 933us/step - loss: 0.1173 - accuracy: 0.9687\n",
      "Epoch 38/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1243 - accuracy: 0.9657\n",
      "Epoch 39/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9677\n",
      "Epoch 40/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9673\n",
      "Epoch 41/200\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9677: 0s - loss: 0.1384 - accuracy: 0.\n",
      "Epoch 42/200\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9690\n",
      "Epoch 43/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9660\n",
      "Epoch 44/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9707\n",
      "Epoch 45/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9683\n",
      "Epoch 46/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9643\n",
      "Epoch 47/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9683\n",
      "Epoch 48/200\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.96 - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9643\n",
      "Epoch 49/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9687\n",
      "Epoch 50/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9677\n",
      "Epoch 51/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9660\n",
      "Epoch 52/200\n",
      "94/94 [==============================] - 0s 997us/step - loss: 0.1156 - accuracy: 0.9680\n",
      "Epoch 53/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9673\n",
      "Epoch 54/200\n",
      "94/94 [==============================] - 0s 976us/step - loss: 0.1142 - accuracy: 0.9690\n",
      "Epoch 55/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1599 - accuracy: 0.9623\n",
      "Epoch 56/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9687\n",
      "Epoch 57/200\n",
      "94/94 [==============================] - 0s 987us/step - loss: 0.1244 - accuracy: 0.9700\n",
      "Epoch 58/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9653\n",
      "Epoch 59/200\n",
      "94/94 [==============================] - 0s 954us/step - loss: 0.1241 - accuracy: 0.9667\n",
      "Epoch 60/200\n",
      "94/94 [==============================] - 0s 975us/step - loss: 0.1203 - accuracy: 0.9680\n",
      "Epoch 61/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9680\n",
      "Epoch 62/200\n",
      "94/94 [==============================] - 0s 965us/step - loss: 0.1163 - accuracy: 0.9693\n",
      "Epoch 63/200\n",
      "94/94 [==============================] - 0s 976us/step - loss: 0.1092 - accuracy: 0.9680\n",
      "Epoch 64/200\n",
      "94/94 [==============================] - 0s 984us/step - loss: 0.1180 - accuracy: 0.9673\n",
      "Epoch 65/200\n",
      "94/94 [==============================] - 0s 950us/step - loss: 0.1078 - accuracy: 0.9713\n",
      "Epoch 66/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9653\n",
      "Epoch 67/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9663\n",
      "Epoch 68/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9657\n",
      "Epoch 69/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9713\n",
      "Epoch 70/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9673\n",
      "Epoch 71/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1173 - accuracy: 0.9700\n",
      "Epoch 72/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9673\n",
      "Epoch 73/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9687\n",
      "Epoch 74/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9653\n",
      "Epoch 75/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9657\n",
      "Epoch 76/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9657\n",
      "Epoch 78/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1179 - accuracy: 0.9677\n",
      "Epoch 79/200\n",
      "94/94 [==============================] - 0s 992us/step - loss: 0.1087 - accuracy: 0.9727\n",
      "Epoch 80/200\n",
      "94/94 [==============================] - 0s 984us/step - loss: 0.1137 - accuracy: 0.9690\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 976us/step - loss: 0.1259 - accuracy: 0.9667\n",
      "Epoch 82/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9697\n",
      "Epoch 83/200\n",
      "94/94 [==============================] - 0s 971us/step - loss: 0.1168 - accuracy: 0.9690\n",
      "Epoch 84/200\n",
      "94/94 [==============================] - 0s 965us/step - loss: 0.1262 - accuracy: 0.9667\n",
      "Epoch 85/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9657\n",
      "Epoch 86/200\n",
      "94/94 [==============================] - 0s 987us/step - loss: 0.1190 - accuracy: 0.9650\n",
      "Epoch 87/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9640\n",
      "Epoch 88/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9687\n",
      "Epoch 89/200\n",
      "94/94 [==============================] - 0s 954us/step - loss: 0.1169 - accuracy: 0.9673\n",
      "Epoch 90/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9677\n",
      "Epoch 91/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1388 - accuracy: 0.9680\n",
      "Epoch 92/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9690\n",
      "Epoch 93/200\n",
      "94/94 [==============================] - 0s 987us/step - loss: 0.1142 - accuracy: 0.9697\n",
      "Epoch 94/200\n",
      "94/94 [==============================] - 0s 973us/step - loss: 0.1136 - accuracy: 0.9690\n",
      "Epoch 95/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9677\n",
      "Epoch 97/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9690\n",
      "Epoch 98/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9703\n",
      "Epoch 99/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9687\n",
      "Epoch 100/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9697\n",
      "Epoch 101/200\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.1150 - accuracy: 0.9683\n",
      "Epoch 102/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1164 - accuracy: 0.9683\n",
      "Epoch 103/200\n",
      "94/94 [==============================] - 0s 879us/step - loss: 0.1309 - accuracy: 0.9643\n",
      "Epoch 104/200\n",
      "94/94 [==============================] - 0s 869us/step - loss: 0.1184 - accuracy: 0.9673\n",
      "Epoch 105/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1100 - accuracy: 0.9683\n",
      "Epoch 106/200\n",
      "94/94 [==============================] - 0s 965us/step - loss: 0.1132 - accuracy: 0.9703\n",
      "Epoch 107/200\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.1420 - accuracy: 0.9637\n",
      "Epoch 108/200\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.1252 - accuracy: 0.9653\n",
      "Epoch 109/200\n",
      "94/94 [==============================] - 0s 976us/step - loss: 0.1323 - accuracy: 0.9657\n",
      "Epoch 110/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9700\n",
      "Epoch 111/200\n",
      "94/94 [==============================] - 0s 944us/step - loss: 0.1264 - accuracy: 0.9663\n",
      "Epoch 112/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9690\n",
      "Epoch 113/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9707\n",
      "Epoch 114/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9687\n",
      "Epoch 115/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9717\n",
      "Epoch 116/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9703\n",
      "Epoch 117/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9677\n",
      "Epoch 118/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9683\n",
      "Epoch 119/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9690\n",
      "Epoch 120/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9673\n",
      "Epoch 121/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9703\n",
      "Epoch 122/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9693\n",
      "Epoch 123/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9697\n",
      "Epoch 124/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9703\n",
      "Epoch 125/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9683\n",
      "Epoch 126/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9683\n",
      "Epoch 127/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9690\n",
      "Epoch 128/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9677\n",
      "Epoch 129/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9693\n",
      "Epoch 130/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9677\n",
      "Epoch 131/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9713\n",
      "Epoch 132/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9727\n",
      "Epoch 133/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9703\n",
      "Epoch 134/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9693\n",
      "Epoch 135/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9690\n",
      "Epoch 136/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9700\n",
      "Epoch 137/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9693: 0s - loss: 0.1152 - accuracy: 0.\n",
      "Epoch 138/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9690\n",
      "Epoch 139/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9690\n",
      "Epoch 140/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9693\n",
      "Epoch 141/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9697\n",
      "Epoch 142/200\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.1105 - accuracy: 0.9720\n",
      "Epoch 143/200\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.1203 - accuracy: 0.9673\n",
      "Epoch 144/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9703\n",
      "Epoch 145/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9677\n",
      "Epoch 146/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9680\n",
      "Epoch 147/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9700\n",
      "Epoch 148/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9690\n",
      "Epoch 149/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9690\n",
      "Epoch 150/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9703\n",
      "Epoch 151/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9703\n",
      "Epoch 152/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9647\n",
      "Epoch 153/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9693\n",
      "Epoch 154/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9707\n",
      "Epoch 155/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9707\n",
      "Epoch 156/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9707\n",
      "Epoch 157/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9710\n",
      "Epoch 158/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9673\n",
      "Epoch 159/200\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9693\n",
      "Epoch 160/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9703\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9687\n",
      "Epoch 162/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9680\n",
      "Epoch 163/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9713\n",
      "Epoch 164/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9693\n",
      "Epoch 165/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9670\n",
      "Epoch 166/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9657\n",
      "Epoch 167/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9693\n",
      "Epoch 168/200\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.96 - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9670\n",
      "Epoch 169/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9697\n",
      "Epoch 170/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9707\n",
      "Epoch 171/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9727\n",
      "Epoch 172/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9700\n",
      "Epoch 173/200\n",
      "94/94 [==============================] - 0s 997us/step - loss: 0.1090 - accuracy: 0.9707\n",
      "Epoch 174/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9687\n",
      "Epoch 175/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9693\n",
      "Epoch 176/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9703\n",
      "Epoch 177/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9717\n",
      "Epoch 178/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9703\n",
      "Epoch 179/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9713\n",
      "Epoch 180/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9700\n",
      "Epoch 181/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9707\n",
      "Epoch 182/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9720\n",
      "Epoch 183/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9710\n",
      "Epoch 184/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9720\n",
      "Epoch 185/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9720\n",
      "Epoch 186/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9710\n",
      "Epoch 187/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9707\n",
      "Epoch 188/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9690\n",
      "Epoch 189/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9707\n",
      "Epoch 190/200\n",
      "94/94 [==============================] - 0s 997us/step - loss: 0.1090 - accuracy: 0.9713\n",
      "Epoch 191/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9720\n",
      "Epoch 192/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9707\n",
      "Epoch 193/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9697\n",
      "Epoch 194/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9723\n",
      "Epoch 195/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9697\n",
      "Epoch 196/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9713\n",
      "Epoch 197/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9700\n",
      "Epoch 198/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9703\n",
      "Epoch 199/200\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9713\n",
      "Epoch 200/200\n",
      "94/94 [==============================] - 0s 987us/step - loss: 0.1041 - accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dfd7526eb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(6, input_shape=(6,) , activation=\"relu\"),\n",
    "    keras.layers.Dense(6, activation=\"relu\"),\n",
    "    keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\" , loss=\"binary_crossentropy\" , metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdd382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "846826e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 874us/step - loss: 0.1025 - accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10245774686336517, 0.9712857007980347]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "428a552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd09cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n",
    "\n",
    "prediction=[]\n",
    "\n",
    "for i in y_pred:\n",
    "    for j in i:\n",
    "        if j>0.5 :\n",
    "            prediction.append(1)\n",
    "        else :\n",
    "            prediction.append(0)\n",
    "        \n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1bfc2907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293     0\n",
       "1244    0\n",
       "7353    0\n",
       "5145    0\n",
       "1618    0\n",
       "       ..\n",
       "5049    0\n",
       "4329    0\n",
       "1315    0\n",
       "843     0\n",
       "7547    0\n",
       "Name: Machine failure, Length: 7000, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "431c7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6763\n",
      "           1       0.76      0.22      0.34       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.87      0.61      0.66      7000\n",
      "weighted avg       0.97      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2a23a",
   "metadata": {},
   "source": [
    "## multilayer perceptron (MLP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b8e575c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=500)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier(max_iter=500, activation='logistic')\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f513f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_fit=mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "840c54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp=model_mlp_fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e7b4be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677142857142857"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16838241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       1.00      0.05      0.09       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.98      0.52      0.54      7000\n",
      "weighted avg       0.97      0.97      0.95      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03b175",
   "metadata": {},
   "source": [
    "Linear regression\n",
    "Logistics Regression\n",
    "Support vector machine (SVM) \n",
    "K nearest neighbors classifier(KNN)\n",
    "Decision Tree Classifier\n",
    "XGBoost Classifier\n",
    "AdaBoostClassifier\n",
    "ANN\n",
    "Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d75f7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      6763\n",
      "           1       0.59      0.23      0.33       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.78      0.61      0.66      7000\n",
      "weighted avg       0.96      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Logistics Regression\n",
    "\n",
    "print(classification_report(y_test,predict_log_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "641f67a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       0.73      0.19      0.31       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.85      0.60      0.65      7000\n",
      "weighted avg       0.96      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Support vector machine (SVM)\n",
    "\n",
    "print(classification_report(y_test,predict_svm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6fc0b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       0.73      0.19      0.31       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.85      0.60      0.65      7000\n",
      "weighted avg       0.96      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## K nearest neighbors classifier(KNN)\n",
    "\n",
    "print(classification_report(y_test,predict_knn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81875e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       0.73      0.19      0.31       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.85      0.60      0.65      7000\n",
      "weighted avg       0.96      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Decision Tree Classifier\n",
    "\n",
    "print(classification_report(y_test,predict_dtc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e124b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       0.73      0.19      0.31       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.85      0.60      0.65      7000\n",
      "weighted avg       0.96      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##XGBoost Classifier\n",
    "\n",
    "print(classification_report(y_test,predict_xgb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa0cb365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6763\n",
      "           1       0.65      0.47      0.54       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.81      0.73      0.76      7000\n",
      "weighted avg       0.97      0.97      0.97      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##AdaBoostClassifier\n",
    "\n",
    "print(classification_report(y_test,predict_ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c023016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6763\n",
      "           1       0.76      0.22      0.34       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.87      0.61      0.66      7000\n",
      "weighted avg       0.97      0.97      0.96      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##ann\n",
    "\n",
    "print(classification_report(y_test,prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01ef6480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6763\n",
      "           1       1.00      0.05      0.09       237\n",
      "\n",
      "    accuracy                           0.97      7000\n",
      "   macro avg       0.98      0.52      0.54      7000\n",
      "weighted avg       0.97      0.97      0.95      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## multilayer perceptron\n",
    "\n",
    "\n",
    "print(classification_report(y_test,pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3059d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f71dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3299c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
